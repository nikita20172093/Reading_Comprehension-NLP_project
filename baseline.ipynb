{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import math\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "import operator\n",
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [\"a\", \"share\", \"linkthese\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\",\"\", \"are\",\"aren't\",\"as\",\"at\",\"be\",\"because\",\"been\",\"before\",\"being\",\"below\",\"between\",\"both\",\"but\",\"by\",\"can't\",\"cannot\",\"could\",\"couldn't\",\"did\",\"didn't\",\"do\",\"does\",\"doesn't\",\"doing\",\"don't\",\"down\",\"during\",\"each\",\"few\",\"for\",\"from\",\"further\",\"had\",\"hadn't\",\"has\",\"hasn't\",\"have\",\"haven't\",\"having\",\"he\",\"he'd\",\"he'll\",\"he's\",\"her\",\"here\",\"here's\",\"hers\",\"herself\",\"him\",\"himself\",\"his\",\"how\",\"how's\",\"i\",\"i'd\",\"i'll\",\"i'm\",\"i've\",\"if\",\"in\",\"into\",\"is\",\"isn't\",\"it\",\"it's\",\"its\",\"itself\",\"let's\",\"me\",\"more\",\"most\",\"mustn't\",\"my\",\"myself\",\"no\",\"nor\",\"not\",\"of\",\"off\",\"on\",\"once\",\"only\",\"or\",\"other\",\"ought\",\"our\",\"ours\",\"ourselves\",\"out\",\"over\",\"own\",\"same\",\"shan't\",\"she\",\"she'd\",\"she'll\",\"she's\",\"should\",\"shouldn't\",\"so\",\"some\",\"such\",\"than\",\"that\",\"that's\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\"then\",\"there\",\"there's\",\"these\",\"they\",\"they'd\",\"they'll\",\"they're\",\"they've\",\"this\",\"those\",\"through\",\"to\",\"too\",\"under\",\"until\",\"up\",\"very\",\"was\",\"wasn't\",\"we\",\"we'd\",\"we'll\",\"we're\",\"we've\",\"were\",\"weren't\",\"what\",\"what's\",\"when\",\"when's\",\"where\",\"where's\",\"which\",\"while\",\"who\",\"who's\",\"whom\",\"why\",\"why's\",\"with\",\"won't\",\"would\",\"wouldn't\",\"you\",\"you'd\",\"you'll\",\"you're\",\"you've\",\"your\",\"yours\",\"yourself\",\"yourselves\", \"this\"]\n",
    "data = \"In 2007 , the country with the highest estimated incidence rate of TB was Swaziland , with 1,200 cases per 100,000 people . India had the largest total incidence , with an estimated 2.0 million new cases . In developed countries , tuberculosis is less common and is found mainly in urban areas . Rates per 100,000 people in different areas of the world were : globally 178 , Africa 332 , the Americas 36 , Eastern Mediterranean 173 , Europe 63 , Southeast Asia 278 , and Western Pacific 139 in 2010 . In Canada and Australia , tuberculosis is many times more common among the aboriginal peoples , especially in remote areas . In the United States Native Americans have a fivefold greater mortality from TB , and racial and ethnic minorities accounted for 84 % of all reported TB cases .\"\n",
    "data2 = \"Bansoori is an Indian classical instrument . Akhil plays Bansoori and Guitar . Puliyogare is a South Indian dish made of rice and tamarind . Priya writes poems . Osmosis is the movement of a solvent across a semipermeable membrane toward a higher concentration of solute . In biological systems, the solvent is typically water, but osmosis can occur in other liquids , supercritical liquids, and even gases . When a cell is submerged in water, the water molecules pass through the cell membrane from an area of low solute concentration to high solute concentration . For example, if the cell is submerged in saltwater, water molecules move out of the cell . If a cell is submerged in freshwater, water molecules move into the cell . Raja-Yoga is divided into eight steps, the first is Yama -- non - killing, truthfulness, non - stealing, continence, and non - receiving of any gifts . Next is Niyama -- cleanliness, contentment, austerity, study, and self - surrender to God.\"\n",
    "data1 = \"A revolution in 1332 resulted in a broad-based city government with participation of the guilds , and Strasbourg declared itself a free republic . The deadly bubonic plague of 1348 was followed on 14 February 1349 by one of the first and worst pogroms in pre-modern history : over a thousand Jews were publicly burnt to death , with the remainder of the Jewish population being expelled from the city . Until the end of the 18th century , Jews were forbidden to remain in town after 10 pm . The time to leave the city was signalled by a municipal herald blowing the Grüselhorn ( see below , Museums , Musée historique ) ; . A special tax , the Pflastergeld ( pavement money ) , was furthermore to be paid for any horse that a Jew would ride or bring into the city while allowed to .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "# splitted corpus with full stop\n",
    "# created list of sentences\n",
    "\n",
    "\n",
    "def pre_process(raw_data):\n",
    "    for c in [',','!',';','?']:\n",
    "        raw_data = raw_data.replace(c,'')\n",
    "    raw_data = raw_data.replace(\" %\",\"%\")\n",
    "\n",
    "    sentences = raw_data.lower().split(\" . \")\n",
    "    processed_sentences = []\n",
    "\n",
    "    for sent in sentences:\n",
    "        sent = list(sent.split())\n",
    "        \n",
    "        for s in sent:\n",
    "            if s not in stopwords:\n",
    "                vocab[s] = vocab.get(s,0) + 1\n",
    "        processed_sentences.append(sent)\n",
    "\n",
    "        \n",
    "    return processed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "#populating dictionaries which will be used to formulate TF-IDF\n",
    "\n",
    "def inverse_dict():\n",
    "    global psent,words_sents_map,total_words_in_sent\n",
    "#     print(psent)\n",
    "    for i in range(0,len(psent)):\n",
    "        temp = {}\n",
    "        count = 0\n",
    "        for word in psent[i]:\n",
    "            if word not in temp:\n",
    "                temp[word] = 1\n",
    "            else:\n",
    "                temp[word] += 1\n",
    "                \n",
    "            if word not  in stopwords:\n",
    "                count += 1\n",
    "       \n",
    "        total_words_in_sent[i] = count\n",
    "        words_sents_map[i] = temp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating TF-IDF against sentences\n",
    "\n",
    "\n",
    "def calc_tf_idf():\n",
    "    global psent,vocab,words_sents_map,total_words_in_sent\n",
    "    global tfidf\n",
    "    \n",
    "    for i in range(len(psent)):\n",
    "        for word in psent[i]:\n",
    "            if(word not in stopwords):        \n",
    "#                 print(words_sents_map[i][word],total_words_in_sent[i])\n",
    "\n",
    "                tf = (words_sents_map[i][word]*1.0)/total_words_in_sent[i]\n",
    "#                 print(tf)\n",
    "                deno = 0\n",
    "                for j in range(len(psent)):\n",
    "                    if(j in words_sents_map and word in words_sents_map[j] and words_sents_map[j][word]!=0):\n",
    "                        deno += 1\n",
    "                        \n",
    "                idf = vocab[word]/deno\n",
    "#                 print(\"idf\",idf)\n",
    "                tf_idf[word] = tf * idf\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question generation\n",
    "# Simple rule based approach\n",
    "# as of now it generates questions starting with \"What\".\n",
    "\n",
    "\n",
    "def genQuestion(line):\n",
    "    \"\"\"\n",
    "    outputs question from the given text\n",
    "    \"\"\"\n",
    "\n",
    "    if type(line) is str:   \n",
    "        line = TextBlob(line) \n",
    "\n",
    "    bucket = {}               # Create an empty dictionary\n",
    "\n",
    "\n",
    "    for i,j in enumerate(line.tags):  \n",
    "        if j[1] not in bucket:\n",
    "            bucket[j[1]] = i  \n",
    "    \n",
    "    \n",
    "    \n",
    "    question = ''            \n",
    "\n",
    "    l1 = ['NNP', 'VBG', 'VBZ', 'IN']\n",
    "    l2 = ['NNP', 'VBG', 'VBZ']\n",
    "    \n",
    "\n",
    "    l3 = ['PRP', 'VBG', 'VBZ', 'IN']\n",
    "    l4 = ['PRP', 'VBG', 'VBZ']\n",
    "    l5 = ['PRP', 'VBG', 'VBD']\n",
    "    l6 = ['NNP', 'VBG', 'VBD']\n",
    "    l7 = ['NN', 'VBG', 'VBZ']\n",
    "\n",
    "    l8 = ['NNP', 'VBZ', 'JJ']\n",
    "    l9 = ['NNP', 'VBZ', 'NN']\n",
    "\n",
    "    l10 = ['NNP', 'VBZ']\n",
    "    l11 = ['PRP', 'VBZ']\n",
    "    l12 = ['NNP', 'NN', 'IN']\n",
    "    l13 = ['NN', 'VBZ']\n",
    "\n",
    "\n",
    "    # With the use of conditional statements the dictionary is compared with the list created above\n",
    "\n",
    "    \n",
    "    if all(key in bucket for key in l1): #'NNP', 'VBG', 'VBZ', 'IN' in sentence.\n",
    "        question = 'What' + ' ' + line.words[bucket['VBZ']] +' '+ line.words[bucket['NNP']]+ ' '+ line.words[bucket['VBG']] + '?'\n",
    "\n",
    "    \n",
    "    elif all(key in  bucket for key in l2): #'NNP', 'VBG', 'VBZ' in sentence.\n",
    "        question = 'What' + ' ' + line.words[bucket['VBZ']] +' '+ line.words[bucket['NNP']] +' '+ line.words[bucket['VBG']] + '?'\n",
    "\n",
    "    \n",
    "    elif all(key in  bucket for key in l3): #'PRP', 'VBG', 'VBZ', 'IN' in sentence.\n",
    "        question = 'What' + ' ' + line.words[bucket['VBZ']] +' '+ line.words[bucket['PRP']]+ ' '+ line.words[bucket['VBG']] + '?'\n",
    "\n",
    "    \n",
    "    elif all(key in  bucket for key in l4): #'PRP', 'VBG', 'VBZ' in sentence.\n",
    "        question = 'What ' + line.words[bucket['PRP']] +' '+  ' does ' + line.words[bucket['VBG']]+ ' '+  line.words[bucket['VBG']] + '?'\n",
    "\n",
    "    elif all(key in  bucket for key in l7): #'NN', 'VBG', 'VBZ' in sentence.\n",
    "        question = 'What' + ' ' + line.words[bucket['VBZ']] +' '+ line.words[bucket['NN']] +' '+ line.words[bucket['VBG']] + '?'\n",
    "\n",
    "    elif all(key in bucket for key in l8): #'NNP', 'VBZ', 'JJ' in sentence.\n",
    "        question = 'What' + ' ' + line.words[bucket['VBZ']] + ' ' + line.words[bucket['NNP']] + '?'\n",
    "\n",
    "    elif all(key in bucket for key in l9): #'NNP', 'VBZ', 'NN' in sentence\n",
    "        question = 'What' + ' ' + line.words[bucket['VBZ']] + ' ' + line.words[bucket['NNP']] + '?'\n",
    "\n",
    "    elif all(key in bucket for key in l11): #'PRP', 'VBZ' in sentence.\n",
    "        if line.words[bucket['PRP']] in ['she','he']:\n",
    "            question = 'What' + ' does ' + line.words[bucket['PRP']].lower() + ' ' + line.words[bucket['VBZ']].singularize() + '?'\n",
    "\n",
    "    elif all(key in bucket for key in l10): #'NNP', 'VBZ' in sentence.\n",
    "        question = 'What' + ' does ' + line.words[bucket['NNP']] + ' ' + line.words[bucket['VBZ']].singularize() + '?'\n",
    "\n",
    "    elif all(key in bucket for key in l13): #'NN', 'VBZ' in sentence.\n",
    "        question = 'What' + ' ' + line.words[bucket['VBZ']] + ' ' + line.words[bucket['NN']] + '?'\n",
    "\n",
    "    # When the tags are generated 's is split to ' and s. To overcome this issue.\n",
    "    if 'VBZ' in bucket and line.words[bucket['VBZ']] == \"’\":\n",
    "        question = question.replace(\" ’ \",\"'s \")\n",
    "\n",
    "    # Print the genetated questions as output.\n",
    "   \n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# finding and sorting sentences with importance in corpus\n",
    "\n",
    "def find_most_imp_sent():\n",
    "    global tf_idf,psent\n",
    "    \n",
    "    most_imp_sent = {}\n",
    "    max_score = 0\n",
    "    for sent in psent:\n",
    "        score = 0\n",
    "        count = 0\n",
    "#         print(sent)\n",
    "        for word in sent:\n",
    "            if word not in stopwords:\n",
    "                count = count + 1\n",
    "                score = score + tf_idf[word]\n",
    "                \n",
    "        if count==0:\n",
    "            score = 0\n",
    "        else:\n",
    "            score /= count\n",
    "        sentence = \" \".join(sent)\n",
    "        most_imp_sent[sentence] = score\n",
    "    sorted_x = sorted(most_imp_sent.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    sorted_x = dict(sorted_x)\n",
    "    return sorted_x\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bansoori is an Indian classical instrument . Akhil plays Bansoori and Guitar . Puliyogare is a South Indian dish made of rice and tamarind . Priya writes poems . Osmosis is the movement of a solvent across a semipermeable membrane toward a higher concentration of solute . In biological systems, the solvent is typically water, but osmosis can occur in other liquids , supercritical liquids, and even gases . When a cell is submerged in water, the water molecules pass through the cell membrane from an area of low solute concentration to high solute concentration . For example, if the cell is submerged in saltwater, water molecules move out of the cell . If a cell is submerged in freshwater, water molecules move into the cell . Raja-Yoga is divided into eight steps, the first is Yama -- non - killing, truthfulness, non - stealing, continence, and non - receiving of any gifts . Next is Niyama -- cleanliness, contentment, austerity, study, and self - surrender to God.\n",
      "\n",
      "\n",
      "('Question: ', 'What is bansoori?')\n",
      "('Answer: ', 'bansoori is an indian classical instrument')\n",
      "\n",
      "\n",
      "('Question: ', 'What is puliyogare?')\n",
      "('Answer: ', 'puliyogare is a south indian dish made of rice and tamarind')\n",
      "\n",
      "\n",
      "('Question: ', 'What is example?')\n",
      "('Answer: ', 'for example if the cell is submerged in saltwater water molecules move out of the cell')\n",
      "\n",
      "\n",
      "('Question: ', 'What writes priya?')\n",
      "('Answer: ', 'priya writes poems')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:82: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    }
   ],
   "source": [
    "#---------------------- MAIN -----------------------------------------\n",
    "\n",
    "vocab = {}\n",
    "words_sents_map = {}\n",
    "total_words_in_sent = {}\n",
    "tf_idf = {}\n",
    "\n",
    "psent = pre_process(data2)\n",
    "#psent = pre_process(data1)\n",
    "\n",
    "inverse_dict()\n",
    "calc_tf_idf()\n",
    "\n",
    "sentence = {}\n",
    "\n",
    "sentence = find_most_imp_sent()\n",
    "\n",
    "length_of_map = len(sentence)\n",
    "\n",
    "length_of_map /= 2;\n",
    "\n",
    "count = 0\n",
    "\n",
    "print(data2) \n",
    "for k,v in sentence.items():\n",
    "    count += 1\n",
    "    line = genQuestion(k)\n",
    "    line = str(line)\n",
    "#     print(line)\n",
    "    if len(line)!=0:\n",
    "        print(\"\\n\")\n",
    "        print(\"Question: \" , line)\n",
    "        print(\"Answer: \",k)\n",
    "    if count >= length_of_map:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Question generation ###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
